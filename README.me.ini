# 音声日記

## 🎯 目的
音声で毎日日記をつけられるようにする。質問がツール側から音声で提案され、答えやすいところから始まり、深掘りができて、最後は前向きな気持ちで終われる枠組みを提供する。

## ✨ コア機能
1. 音声でやりとりするだけで日記が完成する（音声入力＋音声で問いかけ）
2. 質問の流れがある（ウォームアップ→関心事→陰の部分→光の部分→着地）
3. 過去7日分のサマリーが見られる

## 📊 データ構造（超重要）
```javascript
// 配列です
diaryEntries = [
  { 
    id: 1,
    date: "2024-12-02",
    answers: {
      q1: "元気",
      q2: "23:30",
      // ...全15問の回答
    },
    summary: "今日は○○について考えた。△△で少しモヤっとしたが...",
    closingMessage: "明日も一歩ずつ進もう",
    createdAt: "2024-12-02T22:30:00"
  },
  { 
    id: 2,
    date: "2024-12-01",
    answers: {...},
    summary: "...",
    closingMessage: "...",
    createdAt: "2024-12-01T21:45:00"
  }
]
```

**AI指示時の鉄則**: 「diaryEntriesは配列です」

## 📁 ファイル構成
```
├── index.html
├── src/
│   ├── App.jsx
│   ├── components/
│   │   ├── DiaryStarter.jsx      # 会話開始画面
│   │   ├── VoiceChat.jsx         # 音声対話UI
│   │   ├── DiaryResult.jsx       # 完成した日記表示
│   │   └── DiaryList.jsx         # 過去7日分一覧
│   ├── hooks/
│   │   └── useSpeech.js          # 音声入出力カスタムフック
│   ├── utils/
│   │   ├── speechApi.js          # Web Speech API操作
│   │   ├── aiApi.js              # LLM API呼び出し
│   │   └── questions.js          # 質問リスト定義
│   └── data/
│       └── questionList.js       # 15問の質問データ
└── style.css
```

## 🔧 技術構成
- **フレームワーク**: React + Vite
- **音声入力**: Web Speech API (SpeechRecognition)
- **音声出力**: Web Speech API (SpeechSynthesis) or TTS API
- **AI対話**: LLM API（Claude API or OpenAI API）
- **データ保存**: localStorage（Phase 1）
- **理由**: 
  - Reactで状態管理がしやすい
  - Web Speech APIはブラウザ標準で使える
  - Phase 1はAPIキー直書きで個人利用

## 🚫 禁止事項
- ❌ diaryEntries以外のグローバル配列禁止
- ❌ データ構造の変更禁止（常に配列）
- ❌ Phase 1でバックエンド実装禁止（APIキーは直書きでOK）
- ❌ 質問の順番を勝手に変更禁止（questionList.jsに従う）

## 📝 質問リスト（15問）

このツールの核となる15問の質問リストです。Phase 1では固定テキストとして実装します。

### 【ウォームアップ】当たり障りない事実確認（1-5）
1. 「今日は疲れてる？それとも元気？」
2. 「昨日は何時ごろ寝た？」
   - 2-2. 「そういえば、夢見た？覚えてる？」
3. 「今日は何時ごろ起きた？」
4. 「外出した？それとも家にいた？」
5. 「天気どうだった？晴れてた？」

### 【関心の発掘】言いたくてしょうがないこと（6-9）
6. 「今日、頭に残ってることとか気になったこと、何かあった？（例えば見た動画とか、読んだ本とか、やったゲームとか）」
7. 「それってどんな感じだった？」／「それでどうなったの？」
8. 「そこで何か思ったこと、感じたことある？」
9. 「そこから気づいた、何か学びとか、あった？」

### 【陰の部分】聞きづらいこと・もやもや（10-11）
10. 「今日、ちょっとモヤっとしたこととか、イラっとしたことあった？」
    - 10-2. 「そっか、それはモヤっとするね」（共感）or「それって、もうちょっと話したい？それとも次行く？」
11. 「反省したこととか、悔しかったこと、何かある？」
    - 11-2. 「じゃあ、それを次はどうしたい？」or「そこから、何か変えていきたいことある？」

### 【光の部分】理想・やりたいこと（12-13）
12. 「明日、何かやりたいこととか、楽しみなことある？」
13. 「最近、ちょっとワクワクしてることとか、実現したいことある？」

### 【着地】感謝・明日の一歩（14-15）
14. 「今日、ちょっと嬉しかったこととか、良かったことある？」
    - 14-2. 「それって、どうしてよかったんだろう？」
15. 「じゃあ、明日まず何からやってみる？」

**所要時間**: 5-10分想定

## 🔄 Phase 1: MVP（固定質問 + AI要約）

**目標**: 質問リストに沿って音声対話し、AIが日記を生成する

**実装すること**:
- [ ] React環境セットアップ（Vite）
- [ ] questionList.jsに15問を定義
- [ ] Web Speech API（SpeechRecognition）で音声入力
- [ ] Web Speech API（SpeechSynthesis）で音声出力
- [ ] 質問を順番に音声で再生
- [ ] ユーザーの回答を音声→テキスト変換して保存
- [ ] 全回答完了後、LLM APIに送信して日記要約を生成
- [ ] 生成された日記をdiaryEntries配列に保存（localStorage）
- [ ] 過去7日分の日記一覧を表示

**Phase 1の実装詳細:**
```javascript
// questionList.js
export const questions = [
  { id: 1, text: "今日は疲れてる？それとも元気？", category: "warmup" },
  { id: 2, text: "昨日は何時ごろ寝た？", category: "warmup" },
  // ... 15問すべて定義
];

// LLM APIへのプロンプト例
const prompt = `
以下は音声日記の15問への回答です。
今日の出来事、学び、感情、明日のアクションを整理して、
読みやすい日記形式（200-300文字）にまとめてください。
最後は前向きな一言で締めてください。

【回答】
Q1: ${answers.q1}
Q2: ${answers.q2}
...
Q15: ${answers.q15}
`;
```

**Phase 1の特徴:**
- 質問はすべて固定テキスト
- AIは最後の要約生成のみ
- APIコスト最小（Whisper × 15回 + LLM × 1回）
- 安定して動く

---

## ✅ Phase 1完了の確認

以下がすべてできていれば、Phase 1完了です：

□ 会話開始ボタンを押すと質問が音声で流れる
□ マイクボタンで音声入力ができる
□ 15問すべてに回答できる
□ 回答後、AIが日記を生成する
□ 生成された日記と前向きな言葉が表示される
□ 過去7日分の日記が一覧表示される
□ console.logでdiaryEntries配列の中身を確認（配列形式）
□ localStorageにデータが保存されている
□ コンソールにエラーが出ていない

---

## 🤔 Phase 1完了後：次のステップ

当初の目的『音声で日記、質問提案、前向きに終わる』は達成できましたか？

### パターンA: これで完成！（開発終了）

**こんな場合:**
- 固定質問で十分満足
- 毎日使える実用的なツールになった
- シンプルなまま使いたい

**次にやること:**
- 完成です！毎日使ってみましょう
- （任意）Phase 2のバックエンド追加で公開も可能

---

### パターンB: もっと機能を追加したい

**こんな場合:**
- 質問をもっと柔軟にしたい（AI対話を追加）
- ブラウザ履歴から自動で話題を提案してほしい
- デザインをもっと良くしたい
- 公開して他の人にも使ってもらいたい

**⚠️ 重要：Phase 2以降に進む前に**

Phase 1が動いている今の状態を保存しておきましょう。
後で「動いてた時に戻りたい」と思っても、戻れなくなります。

**推奨する方法（どちらか）:**

1. **フォルダごとバックアップ**
   - Phase 1完了時のフォルダを丸ごとコピー
   - 「voice-diary-phase1-backup」のような名前で保存
   - 問題が起きたら、このフォルダから再開

2. **Gitで履歴管理（推奨）**
   - 開発環境で `git init` して履歴管理を開始
   - Phase 1完了時点を `git commit` で保存
   - いつでもこの時点に戻れるようになる
   - ※ Git詳しくない場合は、開発AIに相談してみてください

**バックアップ or Git運用を始めてから、Phase 2へ進んでください。**

---

### Phase 2: 柔軟化（一部AI対話）

**目標**: 質問の一部をAIによる動的な対話に変更

**実装するもの:**
- [ ] 関心の発掘（Q6-9）をAI対話化
  - Q6の回答に応じてQ7-9を動的生成
  - より自然な深掘りが可能に
- [ ] 陰の部分（Q10-11）でAIによる共感表現
  - 回答に応じた共感の言葉を生成
- [ ] その他の質問は固定のまま（安定性重視）

**コストとバランス:**
- APIコール: Whisper × 15 + LLM × 3-5回
- 柔軟性と安定性のバランスが取れる

---

### Phase 3: 完全AI化 + 自動コンテキスト

**目標**: すべての質問をAIが動的に生成＋外部データ連携

**実装するもの:**
- [ ] 全質問のAI動的生成
- [ ] ブラウザ履歴の自動取得と要約
  - 「今日YouTubeでこんな動画見てたみたいだけど、どうだった？」
- [ ] カレンダー連携
  - 「今日は○○さんとの打ち合わせあったよね、どうだった？」
- [ ] 前回日記の参照
  - 「昨日やるって言ってた××、できた？」
- [ ] パーソナライズ学習
  - ユーザーの関心事や言葉遣いを学習
  - 曜日別の傾向を反映

**技術的な追加:**
```
├── api/
│   ├── browserHistory.js    # Chrome Extension API
│   ├── calendar.js           # Google Calendar API
│   └── personalization.js    # ユーザー学習データ
```

**注意:**
- コスト増加（LLM × 20-30回）
- 実装難易度が高い
- でも、超パーソナライズされた体験が実現

---

### バックエンド追加（公開準備）

Phase 1/2/3のどの段階でも、公開したくなったら追加可能：

**追加するもの:**
```
├── api/
│   └── chat.js    # APIキーを安全に管理
├── .env           # 環境変数（APIキー）
└── vercel.json    # デプロイ設定
```

**やること:**
- [ ] api/chat.js作成（サーバーレス関数）
- [ ] 環境変数でAPIキー管理
- [ ] フロントからapi/を呼ぶように変更
- [ ] Vercel等にデプロイ

---

### パターンC: 目的が変わった / 不要になった

**次にやること:**
- 開発を中断してOK
- 学びを記録しておく
- 次のツールアイディアを考える

---

## 📋 その他のアイディア（備忘録）

Phase 1完了後に検討したいアイディアです。

### 参考にしたインタビュー構造
- Anthropicインタビューの対話設計
- ドリームラインの質問フロー
- 共通原理: 答えやすいことから→段階的深掘り→前向きな着地

### 過去の日記テンプレから抽出したアイディア
- ✅ 夢の記録 → Q2-2に実装済み
- ✅ エンタメ消費 → Q6の例示に実装済み
- 🔮 ブラウザ履歴の自動要約 → Phase 3で実装検討
- 🔮 NextActリストの自動生成 → Phase 3で実装検討

### UI/UX改善案
- カラー変更機能
- 音声の速度調整
- 質問のスキップ機能
- 日記の編集機能
- PDFエクスポート

### データ分析機能
- 週間/月間サマリー
- 感情の推移グラフ
- よく出てくるキーワード
- 「あの頃機能」（ランダムで過去日記表示）

これらを実装するかは、Phase 1完了後に判断してください。
不要なら無視してOKです。

---

## 💡 AI指示のコツ
✅ 「diaryEntriesは配列です。新しい日記を追加してください」
✅ 「questionList.jsの順番を守って質問を表示してください」
✅ 「Web Speech APIでSpeechRecognitionを使って音声入力」
✅ 「SpeechSynthesisで音声出力」
✅ 「全15問の回答をLLM APIに渡して日記要約を生成」
✅ 「この〇〇関数を完全に削除してください」（明確な削除指示）
❌ 「音声機能を追加」（曖昧）
❌ 「日記を保存」（どこに？どの形式で？が不明）
❌ 「質問を柔軟に」（Phase 1では禁止、Phase 2以降で検討）